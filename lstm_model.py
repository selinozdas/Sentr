# -*- coding: utf-8 -*-
"""ante_dl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HEN8O3C3W41nh5MLcjuIGNNlli4eQlfR

#Preprocessing
"""

import re


tr_stops = ['ilk','arkadas','adam','kesinlikle','tek','insan','gercekten','sahne','film','bence','bi','filmi','turkcell','a', 'acaba', 'alti', 'altmis', 'ama', 'ancak', 'arada', 'artik', 'aslinda', 'aslinda', 'ayrica', 'az', 'bana', 'bazen', 'bazi', 'bazilari', 'belki', 'ben', 'benden', 'beni',
        'benim', 'beri', 'bes', 'bile', 'bilhassa', 'bin', 'bir', 'biraz', 'bircogu', 'bircok', 'biri', 'birisi', 'birkac', 'birsey', 'biz', 'bizden', 'bize', 'bizi', 'bizim', 'boyle', 
        'boylece', 'bu', 'buna', 'bunda', 'bundan', 'bunlar', 'bunlari', 'bunlarin', 'bunu', 'bunun', 'burada', 'butun', 'cogu', 'cogunu', 'cok', 'cunku', 'da', 'daha', 'dahi', 'dan',
        'de', 'defa', 'diger', 'digeri', 'digerleri', 'diye', 'doksan', 'dokuz', 'dolayi', 'dolayisiyla', 'dort', 'e', 'eden', 'ederek', 'eger', 'elbette', 'elli', 'en', 'etmesi', 
        'ettigi', 'ettigini', 'fakat', 'falan', 'filan', 'gene', 'geregi', 'gerek', 'gibi', 'gore', 'hala', 'halde', 'halen', 'hangi', 'hangisi', 'hani', 'hatta', 'hem', 'henuz', 'hep', 'hepsi',
        'her', 'herhangi', 'herkes', 'herkese', 'herkesi', 'herkesin', 'hic', 'hicbir', 'hicbiri', 'i', 'i', 'icin', 'icinde', 'iki', 'ile', 'ilgili', 'ise', 'iste', 'itibaren', 'itibariyle',
        'kac', 'kadar', 'karsin', 'kendi', 'kendilerine', 'kendine', 'kendini', 'kendisi', 'kendisine', 'kendisini', 'kez', 'ki', 'kim', 'kime', 'kimi', 'kimin', 'kimisi', 'kimse', 'kirk', 
        'madem', 'mi', 'mi', 'milyar', 'milyon', 'mu', 'mu', 'nasil', 'ne', 'neden', 'nedenle', 'nerde', 'nerede', 'nereye', 'neyse', 'nicin', 'nin', 'nin', 'niye', 'nun', 'nun', 'o', 'obur', 'olan', 
        'olarak', 'oldugunu', 'olduklarini', 'olmak', 'olup', 'on', 'ona', 'once', 'ondan', 'onlar', 'onlara', 'onlardan', 'onlari', 
        'onlarin', 'onu', 'onun', 'orada', 'ote', 'oturu', 'otuz', 'oyle', 'oysa', 'pek', 'ragmen', 'sana', 'sanki', 'sanki', 'sayet', 'sekilde', 'sekiz', 'seksen', 'sen', 'senden', 'seni', 'senin',
        'sey', 'seyden', 'seye', 'seyi', 'seyler', 'simdi', 'siz', 'siz', 'sizden', 'sizden', 'size', 'sizi', 'sizi', 'sizin', 'sizin', 'sonra', 'soyle', 'su', 'suna', 'sunlari', 'sunu', 'ta', 'tabii',
        'tam', 'tamam', 'tamamen', 'tarafindan', 'trilyon', 'tum', 'tumu', 'u', 'u', 'uc', 'un', 'un', 'uzere', 'var', 'vardi', 've', 'veya', 'ya', 'yani', 'yapmak',
        'ye', 'yedi', 'yerine', 'yetmis', 'yi', 'yi', 'yine', 'yirmi', 'yoksa', 'yu', 'yuz', 'zaten', 'zira', 'film ', 'filmi ', 'filmin', 'filme', 'filmde', 'gibi', 'bu', 'ben', 'olan', 'diye', 'sadece',
        'sonra', 'her', 'olarak', 'orada', 'orda', 'surda','burda','surada', 'burada', 'hizmet', 'urun', 'etiket', 'film', 'bilgilendirme']
pos_words = ['tesekkur','tebrik','mukemmel','muthis','ilgili','kusursuz','dost','iyi','muthis','harika','idare eder','guzel','akli','aktif','alakadar','alakali','alisilmis','analitik','animsatici','antrenmanli','atak','aydinlatici','ayrintici','bagdastirici','bagimsiz','berk','betimleyici','bilindik','bilinen','bilissel','birinci','bitirim','ciddi',
        'curetkar','cabuk','cocuk ruhlu','cogulcu','cok yonlu','cozumlemeci','dayanakli','denetimli','dengeci','denk','destekci','detayli','diplomali','disiplinli','dogal','dominant','duyarli','dusunceli','eriskin','gercekci','gururlu',
        'haberli','hareketli','hassas','hatirlatici','hesapci','heyecanli','idareci','iddiali','ilgili','itaatkar','itaatli','kararli','kendi halinde','kuralli','mantiksal','metotlu','net','normal','organize','otoriteli','otoriter','olculu','mutevazi','caliskan',
        'oncelikli','parlak','pozitif','sakin','sistematik','sistemli','standartli','tarafsiz','toleransli','uyanik','yardimci','yatistirici','yatkin','dengeli','duygusal','etkili','gonullu','is birlikci','verimli','nazik','komik','bilge','akilli',
        'narin','planli','programli','sabirli','teskilatli','tutkulu','uzlasmaci','aciklayici','becerikli','bilgili','bilincli','cesaretli','dayanikli','degerli','deneyimli','dikkatli','dinamik','disiplinli','duyarli','durust','duzenli','duzeyli',
        'egitimli','gayretli','hazirlikli','sorunsuz','idealist','ileri goruslu','istekli','ise uygun','iyi','kidemli','mantikli','nezaketli','nitelikli','prezantabl','profesyonel','sagduyulu','tedbirli','temkinli','uzman','vasifli','yaratici','adaletli','adil',
        'akilli','caliskan','dakik','enerjik','hakli','kaliteli','optimist','olumlu','rasyonel','tutarli','uyumlu','uretken','verimli','yararli','yardimsever','yenilikci','yetenekli']
neg_words = ['gereksiz','dusman','killik','kusurlu','kusur','nefret','arizali','bozuk','kirik','suratsiz','mahvetti','mahvolmus','kotu','sorun','problem','fena','abartili','acgozlu','adaletsiz','agresif','agzi bozuk','ahlak disi','ahlaksiz','ahmak','ahmakca','akillara zarar','akillanmaz','alayci','aptal','aptalca','ara bozucu','arsiz','art niyetli','asagilik',
        'barbar','bombok','bozgun','bozuk','cani','cildirtici','cozumsuz','daginik','diktator','duzenbaz','duzensiz','eksik','eski','gecersiz','gulunc','gurultu','guvensiz','hadsiz','hain','hevessiz','iki yuzlu','istikrarsiz','islevsiz',
        'kalitesiz','kansiz','karaktersiz','kirilgan','kiskanc','kisiliksiz','kof','korkutucu','korkunc','kullanissiz','limoni','madara','medeniyetsiz','olumsuz','plansiz','problem','ruhsuz','sapik','sarsak','sonucsuz','seytan',
        'tecrubesiz','tekinsiz','tembel','temelsiz','terbiyesiz','ters ters','tertipsiz','tiksindirici','tutarsiz','ukala','utandirici','utanmaz','uyusuk','uyumsuz','uygunsuz','uyduruk','ustunkoru','usengec','uzucu','vahim','verimsiz',
        'yalaka','yalanci','yanlis','yapmacik','yaltak','yaramaz','yararsiz','yilisik','yuz kizartici','asik yuzlu','yuzsuz','zararli','zevksiz','zevzek','zirdeli','zorba',
        'acemi','agir aksak','agzi gevsek','anlayissiz','antipatik','asabi','asalak','asik suratli','asagilayici','avanak','azimsiz','bakimsiz','basiretsiz','basarisiz','beceriksiz','bencil','berbat','bilincsiz','bilmis bilmis',
        'bilgisiz','boktan','bosbogaz','budala','burnu havada','cadaloz','bunaltici','can sikici','ciddiyetsiz','cenesi dusuk','cenesiz','cirkef','cirkin','cokbilmis','dalgaci','dalkavuk','dangalak','dar kafali','darmadaginik',
        'dayaklik','deli','deneyimsiz','demode','degersiz','dedikoducu','despot','disiplinsiz','dikkatsiz','duyarsiz','dusman','duzensiz','eften puften','egitimsiz','embesil','engelli','eski kafali','ezik','felaket','gaddar','gammaz',
        'gayretsiz','gorgusuz','gucsuz','hatali','hilebaz','hosgorusuz','hosnutsuz','huysuz','igrenc','ilkel','incitici','iradesiz','issiz','kaba','kafasiz','kalpsiz','kanunsuz','kirli','korkak','kustah','kusurlu','kompleksli']
mistakes = {'bn':'ben', 'bne':'ben', 'bnm':'benim', 'tsk':'tesekkur', 'deyil':'degil', 'malesef':'maalesef', 'orjinal':'orijinal', 'saol':'sag ol', 'sagol':'sag ol', 'farket':'fark et', 'yanliz':'yalniz', 'yalnis':'yanlis', 'sey':' sey'}

def convertTRLetters(entry):
    tr_char = {'ı':'i','ş':'s','ğ':'g','ö':'o','ç':'c','ü':'u'}
    for key, value in tr_char.items():
        entry = entry.replace(key, value)
    return entry


def removeSpecialChar(entry):
    entry = re.sub(r"[^a-zA-Z ]+", '', entry)
    string_length = len(entry)+1
    entry_revised = entry.ljust(string_length)
    return entry_revised


def fixCommonMistakes(entry):
    entry = entry.split()
    fixed_entry = []
    for word in entry:
        for key, value in mistakes.items():
            if key in word:
                word = word.replace(key,value)
        fixed_entry.append(word)
    entry = ' '.join(fixed_entry)
    string_length = len(entry)+1
    return entry.ljust(string_length)


def removeStopWords(entry):
    entry = ' '.join([word for word in entry.split() if word not in tr_stops])
    string_length = len(entry)+1
    return entry.ljust(string_length)


def removeSuffix(entry):
    entry = entry.split()
    suffixes = ['leri', 'lari',
                'lere', 'lara',
                'ler', 'lar',
                'dim', 'din',
                'tim', 'tin',
                'sin', 'sun',
                'in', 'im', 'u', 'um',
                'iyor', 'uyor', 'yor',
                'imiz', 'umuz',
                'si', 'su',
                'ydir', 'ydur',
                'ydik', 'yduk',
                'ydi', 'ydu',
                'dik' , 'duk',
                'dir', 'dur',
                'di', 'du',
                'tir', 'tur',
                'ti', 'tu',
                'ymis', 'ymus',
                'mis', 'mus',
                'acak', 'ecek',
                'ler', 'lar']
    for suffix in suffixes:
        entry = [word[:-(len(suffix))] if word.endswith(suffix) else word for word in entry]
    return ' '.join(entry)

def extractCommonAdj(entry):
    splitted = entry.split()
    positive = [word for word in splitted if any(pos in word for pos in pos_words)]
    negative = [word for word in splitted if any(neg in word for neg in neg_words)]
    entry = re.sub("|".join(pos_words), " ", entry)
    entry = re.sub("|".join(neg_words), " ", entry)
    string_length = len(entry)+1
    entry = entry.ljust(string_length)
    score = len(positive)-len(negative)
    return positive, negative, entry, score

def preprocess(entry, extract = False):
    entry = entry.lower()
    entry = convertTRLetters(entry)
    entry = removeSpecialChar(entry)
    entry = fixCommonMistakes(entry)
    entry = removeStopWords(entry)
    entry = removeSuffix(entry)
    if extract:
        pos, neg, rest, score = extractCommonAdj(entry)
        return entry, pos, neg, rest, score
    else:
        return entry

"""#Data Split"""


import pandas as pd
import numpy as np
import matplotlib as plt


data = pd.read_excel(r'C:\Users\slnoz\Desktop\Sentiment\train_tweets2.xlsx')
data = data[['content','positivity']]
data['content'] = data['content'].apply(lambda x: preprocess(x))
data = data[data['positivity'] != 2]
data = data[pd.notnull(data['positivity'])]

from sklearn.model_selection import train_test_split
X = data.content
y = data.positivity
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)
print("Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive".format(len(X_train),
                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,
                                                                        (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))
print("Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive".format(len(X_test),
                                                                             (len(X_test[y_test == 0]) / (len(X_test)*1.))*100,
                                                                            (len(X_test[y_test == 1]) / (len(X_test)*1.))*100))

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score
def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):
    sentiment_fit = pipeline.fit(X_train, y_train)
    y_pred = sentiment_fit.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print("accuracy score: {0:.2f}%".format(accuracy*100))
    return accuracy

cv = CountVectorizer()
rf = RandomForestClassifier(class_weight="balanced")
n_features = np.arange(10000,25001,5000)
def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=rf):
    result = []
    print(classifier)
    print("\n")
    for n in n_features:
        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)
        checker_pipeline = Pipeline([
            ('vectorizer', vectorizer),
            ('classifier', classifier)
        ])
        print("Test result for {} features".format(n))
        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)
        result.append((n,nfeature_accuracy))
    return result
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()
print("Result for trigram with stop words (Tfidf)\n")
feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))

from sklearn.metrics import classification_report
cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))
pipeline = Pipeline([
        ('vectorizer', cv),
        ('classifier', rf)
    ])
sentiment_fit = pipeline.fit(X_train, y_train)
y_pred = sentiment_fit.predict(X_test)
print(classification_report(y_test, y_pred, target_names=['negative','positive']))


from sklearn.feature_extraction.text import CountVectorizer
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
import re

max_fatures = 30000
tokenizer = Tokenizer(nb_words=max_fatures, split=' ')
tokenizer.fit_on_texts(data['content'].values)
X1 = tokenizer.texts_to_sequences(data['content'].values)
X1 = pad_sequences(X1)
Y1 = pd.get_dummies(data['positivity']).values
X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, random_state = 42)
print(X1_train.shape,Y1_train.shape)
print(X1_test.shape,Y1_test.shape)

embed_dim = 150
lstm_out = 200
model = Sequential()
model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.2))
model.add(LSTM(lstm_out, dropout_U=0.2,dropout_W=0.2))
model.add(Dense(2,activation='softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])
print(model.summary())
print(classification_report(y_test, y_pred, target_names=['negative','positive']))

batch_size = 32
model.fit(X1_train, Y1_train, epochs = 2, batch_size=batch_size,validation_split=0.33,verbose=2)
'''
pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0
for x in range(len(X1_test)):
    
    result = model.predict(X1_test[x].reshape(1,X1_test.shape[1]),batch_size=1)[0]
    if np.argmax(result) == np.argmax(Y1_test[x]):
        if np.argmax(Y1_test[x]) == 0:
            neg_correct += 1
        else:
            pos_correct += 1      
    if np.argmax(Y1_test[x]) == 0:
        neg_cnt += 1
    else:
        pos_cnt += 1



print("pos_acc", pos_correct/pos_cnt*100, "%")
print("neg_acc", neg_correct/neg_cnt*100, "%")
'''
from keras.models import load_model
model.save('model.h5')
del model